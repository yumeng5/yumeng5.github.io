---
title: "CS 6501 (Spring 2024)"
collection: teaching
permalink: /teaching/2024-spring-cs6501
---



## Schedule

<style>
  table {
    font-size: 14px; /* Set your desired font size */
  }
  th, td {
    padding: 5px; /* Optional: Adjust padding for cells */
  }
</style>

<table>
  <thead>
    <tr>
      <th>Date</th>
      <th>Topic</th>
      <th>Papers</th>
      <th>Slides</th>
      <th>Recommended Reading</th>
    </tr>
  </thead>
  <tr>
      <td colspan="5" align="center"><b>Introduction to Language Models</b></td>
  </tr>
  <tbody>
    <tr>
      <td>1/17</td>
      <td>Course Overview</td>
      <td>-</td>
      <td>overview</td>
      <td>-</td>
    </tr>
    <tr>
      <td>1/22</td>
      <td>Language Model Architecture and Pretraining</td>
      <td>
        * <a href="https://arxiv.org/abs/1310.4546">Distributed Representations of Words and Phrases and their Compositionality (word2vec) </a><br>
        * <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need (Transformer)</a><br>
        * <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners (GPT-2)</a> <br>
        * <a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><br>
        * <a href="https://arxiv.org/abs/1910.13461">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a><br> 
        * <a href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5) </a> <br> </td>
      <td>lm_basics</td>
      <td> 
        * <a href="https://jalammar.github.io/illustrated-transformer/">(Blog) The Illustrated Transformer</a><br> 
        * <a href="https://kipp.ly/transformer-inference-arithmetic/">(Blog) Transformer Inference Arithmetic</a><br> </td>
    </tr>
    <tr>
      <td>1/24</td>
      <td> Large Language Models and In-Context Learning </td>
      <td>
        * <a href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners (GPT-3) </a><br>
        * <a href="https://arxiv.org/abs/2307.09288">Llama 2: Open Foundation and Fine-Tuned Chat Models </a><br>
        * <a href="https://arxiv.org/abs/2111.02080">An Explanation of In-context Learning as Implicit Bayesian Inference </a><br>
        * <a href="https://arxiv.org/abs/2202.12837">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? </a><br>
      </td>
      <td>  </td>
      <td> <a href="https://www.interconnects.ai/p/llama-2-from-meta">(Blog) Llama 2: an incredible open LLM</a><br> </td>
    </tr>
    <tr>
      <td>1/29</td>
      <td> Scaling and Emergent Ability </td>
      <td>
        * <a href="https://arxiv.org/abs/2203.15556">Training Compute-Optimal Large Language Models </a><br>
        * <a href="https://arxiv.org/abs/2305.16264">Scaling Data-Constrained Language Models</a><br>
        * <a href="https://arxiv.org/abs/2206.07682">Emergent Abilities of Large Language Models </a><br>
        * <a href="https://arxiv.org/abs/2304.15004">Are Emergent Abilities of Large Language Models a Mirage?</a><br>  
      </td>
      <td>  </td>
      <td>  </td>
    </tr>
  </tbody>
  
  
  <tr>
      <td colspan="5" align="center"><b>Reasoning with Language Models</b></td>
  </tr>
  <tbody>
  <tr>
      <td> date </td>
      <td> Chain-of-Thought Generation </td>
      <td>
        * <a href="https://arxiv.org/abs/2201.11903">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models </a><br>
        * <a href="https://arxiv.org/abs/2305.10601">Tree of Thoughts: Deliberate Problem Solving with Large Language Models </a><br>
        * <a href="https://arxiv.org/abs/2203.11171">Self-Consistency Improves Chain of Thought Reasoning in Language Models </a><br>
        * <a href="https://arxiv.org/abs/2210.11610">Large Language Models Can Self-Improve </a><br>
      </td>
      <td> </td>
  </tr>
  <tr>
      <td> date </td>
      <td> Advanced Reasoning </td>
      <td>
        * <a href="https://arxiv.org/abs/2211.10435">PAL: Program-aided Language Models </a><br>
      </td>
      <td> </td>
      <td>  </td>
  </tr>
  </tbody>
  
  
  <tr>
      <td colspan="5" align="center"><b>Language Model Alignment</b></td>
  </tr>
  <tbody>
  <tr>
      <td> date </td>
      <td> Multi-Task Instruction Tuning </td>
      <td>
        * <a href="https://arxiv.org/abs/2109.01652">Finetuned Language Models Are Zero-Shot Learners </a><br>
        * <a href="https://arxiv.org/abs/2110.08207">Multitask Prompted Training Enables Zero-Shot Task Generalization </a><br>
        * <a href="https://arxiv.org/abs/2104.08773">Cross-Task Generalization via Natural Language Crowdsourcing Instructions </a><br>
        * <a href="https://arxiv.org/abs/2204.07705">Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks </a><br>
      </td>
      <td> </td>
      <td> <a href="https://yaofu.notion.site/June-2023-A-Stage-Review-of-Instruction-Tuning-f59dbfc36e2d4e12a33443bd6b2012c2">(Blog) A Stage Review of Instruction Tuning</a><br> </td>
  </tr>
  <tr>
      <td> date </td>
      <td> Chat-Based Instruction Tuning </td>
      <td>
        * <a href="https://arxiv.org/abs/2212.10560">Self-Instruct: Aligning Language Models with Self-Generated Instructions </a><br>
        * <a href="https://arxiv.org/abs/2305.11206">LIMA: Less Is More for Alignment </a><br>
        * <a href="https://arxiv.org/abs/2305.14387">AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback </a><br>
      </td>
      <td> </td>
      <td> </td>
  </tr>
  <tr>
      <td> date </td>
      <td> Reinforcement Learning from Human Feedback (RLHF) </td>
      <td>
        * <a href="https://arxiv.org/abs/2203.02155">Training language models to follow instructions with human feedback </a><br>
        * <a href="https://arxiv.org/abs/2305.18290">Direct Preference Optimization: Your Language Model is Secretly a Reward Model </a><br>
        * <a href="https://arxiv.org/abs/2306.01693">Fine-Grained Human Feedback Gives Better Rewards for Language Model Training </a><br>
        * <a href="https://arxiv.org/abs/2311.10702">Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2 </a><br>
      </td>
      <td> </td>
      <td> </td>
  </tr>
  
  </tbody>
  
  
  <tr>
      <td colspan="5" align="center"><b>Retrieval-Agumented Language Generation</b></td>
  </tr>
  
  
</table>

