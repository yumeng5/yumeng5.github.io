---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Ph.D. candidate at University of Illinois Urbana-Champaign (UIUC). My advisor is [Jiawei Han](http://hanj.cs.illinois.edu/). Currently, I am visiting Princeton NLP Group, working with [Danqi Chen](https://www.cs.princeton.edu/~danqic/). I am grateful for being supported by the [Google PhD fellowship](https://research.google/outreach/phd-fellowship/recipients/?category=2021) since 2021.

<span style="color:blue">**I will join the Computer Science Department at the University of Virginia (UVA) as an assistant professor in January 2024. I am looking for PhD students! Please send me an email with your CV and transcripts if you are interested in working with me (I will read all emails but I do apologize for not being able to respond to each of them)!**</span>

Research
======

I am broadly interested in the fields of natural language processing (NLP), machine learning (ML), and data mining. I am especially passionate about the following research directions (with some past work as examples):  
* **Representation Learning in NLP**:
  * [arXiv'23 Meng et al.] [Representation Deficiency in Masked Language Modeling](https://arxiv.org/abs/2302.02060)
  * [ICLR'22 Meng et al.] [Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators](https://arxiv.org/abs/2204.03243)
  * [NeurIPS'21 Meng et al.] [COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining](https://arxiv.org/abs/2102.08473)
  * [NeurIPS'19 Meng et al.] [Spherical Text Embedding](https://arxiv.org/abs/1911.01196)
* **Large Language Models for Few-Shot and Zero-Shot Learning**:
  * [ICML'23 Meng et al.] [Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning](https://arxiv.org/abs/2211.03044)
  * [NeurIPS'22 Meng et al.] [Generating Training Data with Language Models: Towards Zero-Shot Language Understanding](https://arxiv.org/abs/2202.04538)
* **Text Mining Paradigms and Applications**:
  * [WWW'22 Meng et al.] [Topic Discovery via Latent Space Clustering of Pretrained Language Model Representations](https://arxiv.org/abs/2202.04582)
  * [EMNLP'20 Meng et al.] [Text Classification Using Label Names Only: A Language Model Self-Training Approach](https://arxiv.org/abs/2010.07245)
  * [CIKM'18 Meng et al.] [Weakly-Supervised Neural Text Classification](https://arxiv.org/abs/1809.01478)


News
======

* \[**2023.05**\] One paper on [Weakly Supervised Scientific Text Classification]() has been accepted by **KDD 2023**!

* \[**2023.05**\] Two papers on [Language Model Pretraining on Text-Rich Network](https://arxiv.org/abs/2305.12268) and [Retrieval-Enhanced Weakly-Supervised Text Classification](https://arxiv.org/abs/2305.10703) have been accepted by **ACL 2023 Main Conference/Findings**!

* \[**2023.04**\] Our tutorial on [Pretrained Language Representations for Text Understanding](https://yumeng5.github.io/kdd23-tutorial/) has been accepted by **KDD 2023**!

* \[**2023.04**\] One paper on [Few-Shot Learning](https://arxiv.org/abs/2211.03044) has been accepted by **ICML 2023**!

* \[**2023.01**\] Two papers on [Metadata-Enhanced Scientific Text Classification](https://arxiv.org/abs/2302.03341) and [Unsupervised Online Story Discovery](https://dl.acm.org/doi/abs/10.1145/3543507.3583507) have been accepted by **WWW 2023**!

* \[**2023.01**\] One paper on [Learning Text-Rich Network Representations](https://arxiv.org/abs/2302.11050) has been accepted by **ICLR 2023**!

* \[**2022.12**\] Our tutorial on [Turning Web-Scale Texts to Knowledge: Transferring Pretrained Representations to Text Mining Applications](https://yumeng5.github.io/www23-tutorial/) has been accepted by **WWW 2023**!

* \[**2022.10**\] Two papers on [Seed-Guided Topic Discovery](https://arxiv.org/abs/2212.06002) and [Opion Summary](https://arxiv.org/abs/2110.08845) have been accepted by **WSDM 2023**!

* \[**2022.09**\] One paper on [Zero-Shot Language Understanding](https://arxiv.org/abs/2202.04538) has been accepted by **NeurIPS 2022**!


Education
======
* Ph.D. (Expected 2023) in Computer Science, University of Illinois Urbana-Champaign  
Advisor: Prof. [Jiawei Han](http://hanj.cs.illinois.edu/)

* M.S. (2019) in Computer Science, University of Illinois Urbana-Champaign  
Advisor: Prof. [Jiawei Han](http://hanj.cs.illinois.edu/), \[[Thesis](https://www.ideals.illinois.edu/handle/2142/104867)\]

* B.S. (2017) in Computer Engineering, University of Illinois Urbana-Champaign  
Graduated with Highest Honor & [Bronze Tablet](https://digital.library.illinois.edu/items/592ebe50-1be8-0136-4cfa-0050569601ca-5#?c=0&m=0&s=0&cv=0&r=0&xywh=-3461%2C0%2C12837%2C5932)  
Advisor: Prof. [Sayan Mitra](http://mitras.ece.illinois.edu/)

Contact
======
* Email: yumeng5\[at\]illinois\[dot\]edu

* Office: Room 1113, Thomas M. Siebel Center, 201 N. Goodwin Avenue, Urbana, IL 61801
